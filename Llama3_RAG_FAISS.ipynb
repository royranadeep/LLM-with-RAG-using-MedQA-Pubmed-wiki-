{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedQA Dataset parsing for English data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T10:05:11.532755Z",
     "iopub.status.busy": "2024-07-12T10:05:11.532199Z",
     "iopub.status.idle": "2024-07-12T10:05:15.511848Z",
     "shell.execute_reply": "2024-07-12T10:05:15.511048Z",
     "shell.execute_reply.started": "2024-07-12T10:05:11.532724Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def read_question_answer_file(file_path):\n",
    "    \"\"\"Reads a JSONL file with question-answer data and returns a list of dictionaries.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))  # Parse each line as JSON\n",
    "    return data\n",
    "\n",
    "# Load your dataset\n",
    "dataset_path = r'C:\\Users\\ranad\\OneDrive - University of Glasgow\\Attachments\\Msc Final Year project\\Data\\MedQA-USMLE-4-options\\phrases_no_exclude_train.jsonl'  # Replace with the path to your JSON file\n",
    "questions_data = read_question_answer_file(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T10:05:17.983043Z",
     "iopub.status.busy": "2024-07-12T10:05:17.982532Z",
     "iopub.status.idle": "2024-07-12T10:05:17.988651Z",
     "shell.execute_reply": "2024-07-12T10:05:17.987532Z",
     "shell.execute_reply.started": "2024-07-12T10:05:17.983007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?\n",
      "D\n",
      "{'A': 'Ampicillin', 'B': 'Ceftriaxone', 'C': 'Doxycycline', 'D': 'Nitrofurantoin'}\n"
     ]
    }
   ],
   "source": [
    "print(questions_data[0]['question'])\n",
    "print(questions_data[0]['answer_idx'])\n",
    "print(questions_data[0]['options'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data pre-processing and extraction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"Removes special characters and extra whitespace from text.\n",
    "\n",
    "  Args:\n",
    "    text: The input text to be cleaned.\n",
    "\n",
    "  Returns:\n",
    "    The cleaned text.\n",
    "  \"\"\"\n",
    "  # Remove special characters, but keep letters, digits, and single spaces\n",
    "  cleaned_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "  cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    # Strip leading and trailing spaces (if any)\n",
    "  cleaned_text = cleaned_text.strip()\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_string_to_file(data, filename):\n",
    "  \"\"\"Saves a string to a text file.\n",
    "\n",
    "  Args:\n",
    "    text: The string to be saved.\n",
    "    filename: The name of the file to create.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(filename, \"w\",encoding='utf-8') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# # Example usage:\n",
    "# my_string = \"This is the text I want to save.\"\n",
    "# save_string_to_file(my_string, \"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename):\n",
    "  \"\"\"Sanitizes a filename by replacing special characters with underscores.\n",
    "\n",
    "  Args:\n",
    "    filename: The original filename.\n",
    "\n",
    "  Returns:\n",
    "    The sanitized filename.\n",
    "  \"\"\"\n",
    "\n",
    "  # Replace non-alphanumeric characters with underscores\n",
    "  filename = re.sub(r'[^\\w]', '_', filename)\n",
    "\n",
    "  # Remove leading and trailing underscores\n",
    "  filename = filename.strip('_')\n",
    "\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_text(data):\n",
    "  \"\"\"Extracts text from the given JSON data.\n",
    "\n",
    "  Args:\n",
    "    data: The JSON data.\n",
    "\n",
    "  Returns:\n",
    "    A list of text strings.\n",
    "  \"\"\"\n",
    "\n",
    "  texts = []\n",
    "  for document in data:\n",
    "    for passage in document['documents'][0]['passages']:  # Access the first document's passages\n",
    "        words = passage['text'].split()\n",
    "        if(len(words)> 10):\n",
    "          texts.append(clean_text(passage['text']))\n",
    "  return texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generate bert embeddings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Initialize the tokenizer and model (bert-base-uncased)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Ensure the model runs on GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model.to(device)\n",
    "\n",
    "\n",
    "# Function to compute embeddings\n",
    "def get_embeddings(text,tokenizer,model):\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    embeddings = last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compute the mean of the token embeddings to get a fixed-size representation\n",
    "    embeddings = embeddings.squeeze().cpu().numpy()  # (batch size x hidden size)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dictionary format data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing JSON files\n",
    "pubmed_dir = 'C:/Users/ranad/Documents/Pubmed_Full_text/'\n",
    "\n",
    "# Dictionary to store the original data (not embeddings) by file key\n",
    "\n",
    "\n",
    "def extract_dataDict(directory):\n",
    "    data_dict = {}\n",
    "    # Iterate through each JSON file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            file_key = sanitize_filename(filename[:-4])  \n",
    "            data_dict[file_key] = data\n",
    "    return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = extract_dataDict(pubmed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Osteoarthritis is the most common form of arthritis and a leading cause of disability worldwide largely due to pain the primary symptom of the disease The pain experience in knee osteoarthritis in particular is wellrecognized as typically transitioning from intermittent weightbearing pain to a more persistent chronic pain Methods to validly assess pain in osteoarthritis studies have been developed to address the complex nature of the pain experience The etiology of pain in osteoarthritis is recognized to be multifactorial with both intraarticular and extraarticular risk factors Nonetheless greater insights are needed into pain mechanisms in osteoarthritis to enable rational mechanismbased management of pain Consequences of pain related to osteoarthritis contribute to a substantial socioeconomic burden',\n",
       "  'The hallmark symptom of osteoarthritis OA the most common form of arthritis is pain This is the symptom that drives individuals to seek medical attention and contributes to functional limitations and reduced quality of life Largely because of pain lower extremity OA is wellrecognized as the leading cause of mobility impairment in older adults in the US',\n",
       "  'Approximately 27 million US adults and 85 million UK adults are estimated to have clinical OA defined on the basis of symptoms and physical findings Prevalence of OA increases with age 139 of adults age 25 and older have clinical OA of at least one joint while 336 of adults age 65 and older have OA',\n",
       "  'In large epidemiologic studies OA is often defined on the basis of standard radiographic assessments such as the Kellgren and Lawrence grade Symptomatic OA indicates the presence of both radiographic OA and symptoms ie pain aching stiffness in the same joint attributable to OA as such its prevalence is generally lower than that of radiographic OA ie regardless of symptoms For example the prevalence of radiographic knee OA was 19 and 28 among adults age 45 years in the Framingham study and Johnston County Osteoarthritis Project respectively while the prevalence of symptomatic knee OA was 7 in Framingham and 17 in the Johnston County Osteoarthritis Project The prevalence of symptomatic knee OA in two UK studies ranged from 1119 and estimates of 515 were noted in surveys undertaken in other countries',\n",
       "  'Symptomatic hip OA has been reported to be 9 in the Johnston County Osteoarthritis Project with lower prevalence estimates of 0744 in the UK The prevalence of symptomatic hand OA is higher with the agestandardized prevalence of symptomatic hand OA being 144 and 69 in women and men respectively in younger Framingham cohorts increasing to 262 and 134 respectively among those age 71 in an older Framingham cohort Another study reported an estimate of 8 among adults age 60 and older Incidence of symptomatic hand OA were reported to be 97 for women and 4 for men over a 9year period',\n",
       "  'The lifetime risk of developing symptomatic knee OA is estimated to be 45 40 in men and 47 in women based upon Johnston County Osteoarthritis Project data with risks increasing to 605 among persons who are obese which is approximately double the risk of those who are of normal weight or are underweight With aging of the population and increasing obesity the prevalence of OA is expected to rise Indeed an increase in prevalence of symptomatic knee OA over the past 20 years has been noted in the Framingham cohort rising by 41 and 6 among women and men respectively intriguingly without a concomitant parallel rise in prevalence of radiographic OA Based upon National Health Interview Survey NHIS data the estimated number of US adults with doctordiagnosed arthritis the majority of which is related to OA and likely symptomatic if it has had medical attention is projected to increase to nearly 67 million by 2030',\n",
       "  'Clearly a substantial proportion of adults experience pain related to OA during their lifetime Further individuals with OA in one joint will often have OA in another joints with resulting greater symptomatic burden of the disease',\n",
       "  'The International Association for the Study of Pain defines pain as an unpleasant sensory and emotional experience associated with actual or potential tissue damage or described in terms of such damage It is a complex subjective phenomenon with each individual having a unique perception of it influenced by biological psychological and social factors Under normal circumstances pain is a warning that something is wrong pain from touching a hot stove having injured a joint or chest pain due to ischemia for example In these instances pain plays a protective role signaling to the individual to withdraw from the threat rest to allow tissue healing or seek help etc However once its warning role is over persistence or continued pain ie chronic pain is considered maladaptive',\n",
       "  'Unlike many other pain conditions in which the underlying injury typically heals or resolves OA is a disease that does not resolve Thus OA is typically accompanied by chronic pain Whether and to what degree this ongoing chronic pain i plays an important nociceptive role ii represents maladaptive pain or iii reflects other aspects of the pain experience is not clear',\n",
       "  'The pain experience among persons with OA has been evaluated through a number of qualitative research efforts In the first qualitative study to focus explicitly on pain and related distress as well as changes in pain over time by Hawker et al individuals with hip and knee OA identified two distinct types of OA pain one that was intermittent but generally severe or intense and another that was a persistent background pain or aching Stages of OArelated pain could be discerned with early stages characterized by activityrelated pain becoming more constant over time and punctuated by intermittent intense pain A decrease in participation subsequently occurs in an attempt to avoid triggering such episodes The more intense but less frequent pain that comes and goes ie intermittent particularly when unpredictable had greater impact on quality of life than the background ie constant pain The pain had negative effects on mood participation in social and recreational activities and sleep Similar findings were noted in another study of individuals who had a recent diagnosis of knee OA or were symptomatic but undiagnosed ie prediagnostic knee OA The significance of intermittent knee symptoms was not clear for several years before participants became aware of development of chronic knee symptoms They then altered activities to avoid more symptoms until symptoms affected participation at which time they sought medical care',\n",
       "  'In addition to the concepts of intermittent and constant pain the intensity of daily pain varies widely although the underlying reasons for such variation are not wellunderstood The quality of pain in OA also varies with approximately onethird of individuals with knee OA using descriptors such as burning tingling numbness and pins and needles to characterize their knee symptoms Such descriptors suggest that neuropathic pain may contribute to the OA pain experience although specific nerve lesions have not been identified in OA',\n",
       "  'Given the variation in pain intensity frequency pattern and quality in OA a single simple question about pain is unlikely to adequately capture the full pain experience Some of the variation in reported prevalence of symptomatic OA is related to differences in study design and populations examined but importantly it is also due to the way in which questions about knee pain were formulated Differences in descriptors used to assess pain eg pain vs pain aching or stiffness may elicit different responses Duration over which pain is being assessed eg pain on most days of a month in the past year vs pain on most days of the past month can be prone to recall bias Ideally uniform standardized and valid questionnaires should be used to evaluate pain particularly to enable more precise pain phenotyping and facilitate crossstudy comparisons genetic association studies and drug trial protocol development',\n",
       "  'In OA cohort studies and trials a number of approaches are typically used to assess pain For evaluation of knee OA pain the most common are a visual analog scale VAS or numerical rating scale NRS assessment of pain intensity a single question about presence of pain aching of stiffness in or around the knee over a specified period of time andor the pain subscale of the Western Ontario and McMaster Universities Arthritis Index WOMAC or the Knee injury and Osteoarthritis Outcome Score KOOS The pain subscales of these latter two instruments assess pain experienced with specific activities As a result the pain and function subscale scores are highly correlated Nonetheless these validated instruments are responsive and are used in assessing efficacy of interventions A number of additional validated generic pain instruments are available that are also appropriate for use in OA A metaanalysis concluded that different patientreported outcome measures of pain severity have generally comparable responsiveness to treatment with the singleitem pain assessments with the VAS or NRS resulting in effect estimates comparable to the WOMAC pain subscale although their mean standardized effect sizes were lower To enable meaningful interpretation of response to therapy rather than relying on mean group responses the OMERACTOARSI set of responder criteria were developed and validated for use in clinical trials To be considered a responder at least a minimum threshold of relative and absolute improvement in pain or a lesser degree of absolute and relative improvement in at least 2 out of 3 domains pain function patient global assessment is required Many of these same questions and instruments eg WOMAC can be used for hip OA the Hip disability and Osteoarthritis Outcome Score HOOS is specific for hip OA To assess pain stiffness and physical functioning in hand OA the AustralianCanadian Osteoarthritis Hand Index AUSCAN is commonly used',\n",
       "  'Despite widespread use of these pain assessments the complex pain experience of those living with OA is not adequately captured by existing measures To address this issue a multicenter international OARSIOMERACT initiative led to development of a new measure informed by qualitative research findings that was subsequently validated This new instrument ICOAP Intermittent and Constant OA Pain assesses various facets regarding both intermittent and constant pain for the knee and hip separately including frequency for intermittent pain intensity effects on sleep and quality of life degree of frustration or annoyance and upset or worried feelings associated with the pain as well as whether the intermittent pain occurs without warning or after a trigger The ICOAP has recently been demonstrated to be responsive to change in intervention studies',\n",
       "  'In keeping with the acknowledgement of the multidimensional nature of pain the Initiative on Methods Measurement and Pain Assessment in Clinical Trials IMMPACT has recommended six core domains and associated measures that should be considered when studying any type of chronic pain in clinical trials pain intensity and use of rescue medications physical functioning with a focus on pain interference emotional functioning participant ratings of improvement and satisfaction with treatment symptoms and adverse events and participant disposition Other domains related to pain in OA include fatigue sleep and cognition With the increasing importance of patientreported outcomes the NIHfunded Patient Reported Outcomes Measurement Information System PROMIS provides an opportunity to collect a variety of validated patientreported health outcomes related to physical mental and social wellbeing in addition to pain',\n",
       "  'In view of the complex multidimensional nature of the pain experience in OA it is perhaps not surprising that the underlying etiology of pain is multifactorial most often considered in a biopsychosocial framework Figure 1 A few such risk factors are discussed below',\n",
       "  'The extent to which structural pathology in OA contributes to the pain experience has been controversial A structuresymptom discordance in OA has been widely noted based upon observations of weak correlations between radiographic severity of OA and pain presence or severity although the discordance is less with more severe stages of radiographic disease In a systematic review 1576 of those with knee pain had radiographic OA and 1581 of those with radiographic OA had knee pain The extent of additional xray views obtained the definition of pain symptoms and the nature of the study sample eg age race affected the prevalence of these findings and therefore interpretation of the degree of concordance For example in studies evaluating both the tibiofemoral and patellofemoral joints that also obtained WOMAC pain assessments a more consistent association was noted between pain severity and radiographic OA Supporting such findings a randomized trial demonstrated intraarticular lidocaine to effectively decrease knee pain in comparison with placebo lending further support to the notion that structural pathology within the knee must be contributing to pain',\n",
       "  'Beyond measurement issues there are additional reasons that contribute to an apparent discordance As discussed above pain is a subjective experience influenced by a number of factors including genetic predisposition prior experience expectations about analgesic treatment current mood coping strategies and catastrophizing and sociocultural environment as some examples Without taking into account such factors that can contribute to betweenperson differences assessment of the relation of structure to symptoms will be confounded Unfortunately most such factors that contribute to individual variation in pain cannot be feasibly measured or collected in most studies By adequately controlling for betweenperson differences using a withinperson kneematched approach a strong doseresponse relationship can be demonstrated between radiographic severity and pain presence severity and incidence ie new onset',\n",
       "  'While such studies provide confirmation that structural pathology of OA does indeed contribute to the pain experience radiographs do not provide insight into what particular structural pathologies may contribute to such pain A review elsewhere in this issue examines the structural correlates of pain in greater detailREF In brief based upon MRI studies bone marrow lesions synovitis and effusions appear to have the greatest evidence supporting their relation to pain in OA to date',\n",
       "  'Although such studies have highlighted the importance of structural pathology to pain in OA attempts at structure modification have been largely unsuccessful to date with regards to pain Some recent exceptions include promising pain results from trials evaluating zoledronic acid targeting bone marrow lesions with possible additional bone and cartilage effects and strontium ranelate which may have both bone and cartilage effects',\n",
       "  'Other risk factors for pain in OA may be more amenable to modification Psychological factors are wellrecognized as being correlated with pain in OA and the role of cognitive behavioural therapy is outlined elsewhere in this issue REF Specifically some traits such as catastrophizing coping and selfefficacy may be amenable to intervention While depression anxiety and negative affect among others have been associated with OA pain the causal direction of such relationships is difficult to discern Fluctuation in pain has been linked to fluctuation in psychological factors but whether the pain influences the mood or vice versa is difficult to disentangle Although psychological factors can certainly contribute to a heightened pain experience it is also possible that pain itself can contribute to poor mood Such relationships can only be discerned from longitudinal studies of which there are relatively few to date For example pain from OA contributed to functional limitations and fatigue which in turn contributed to depressed mood and worse pain and function in one study evaluating these complex interrelationships Functional brain imaging studies of OA also demonstrate an important role of affective and motivational aspects of pain that should be addressed to improve effective management of OArelated pain This is particularly important in light of the prevalence and impact of comorbid mood disorders on health outcomes',\n",
       "  'Weight is a potential modifiable factor contributing not only to OA risk but also to pain The effect of obesity on pain may be twofold For the lower extremities the effect of excess weights on symptoms may be due to mechanical loading Increased relative fat mass in obesity may potentially contribute to pain symptoms related to elaboration of adipokines although studies are conflicting in this regard While the mechanism by which obesity contributes to pain may not be clear effects of altering weight on OArelated pain have been studied Observational cohort data was used to demonstrate a lower risk of developing symptomatic knee OA among women who lost 5kg Subsequent randomized trials have noted reductions in pain with 10 weight loss with more substantial effects on pain reduction with greater weight loss Importantly weight gain significantly increases pain highlighting the doseresponse relationship of change in weight with change in pain',\n",
       "  'While not directly modifiable there may be a genetic predisposition to development of chronic pain or experiencing greater pain severity that may provide insight into novel therapeutic targets The availability of large cohort studies with standardized pain and xray data has facilitated genetic association studies to address such hypotheses A functional polymorphism Val158Met in the COMT gene which has been associated with pain sensitivity in other clinical conditions was associated with hip OArelated pain in one cohort study but has not yet been replicated in other cohorts TRPV1 and the PACE4 gene PCSK6 were associated with pain in knee OA in two separate metaanalyses while an association with a SCN9 SNP could not be replicated A missense variant in P2RX7 a target identified through a genomewide screen in mice with assessment of mechanical allodynia has been associated with OArelated pain in one cohort Greater details of genetic determinants of pain can be found elsewhere in this issueREF',\n",
       "  'Another area that may provide potential therapeutic targets is related to risk factors that contribute to the transition from acute to chronic pain in OA which at present is not wellunderstood As noted in the qualitative work described above there is a general progression of symptoms from the early stages of OA with activityrelated eg weightbearing symptoms that appear to be nociceptive in nature to a more persistent constant pain that likely reflects other additional processes such as neurobiological mechanisms Tissue injury andor inflammation as may be seen in OA leads to a decrease in the excitation threshold and an increase in responsiveness to suprathreshold stimuli of peripheral nociceptors ie peripheral sensitization Noxious mechanical stimuli can then evoke exaggerated responses primary hyperalgesia and normally innocuous stimuli such as movement of the joint through its normal range of motion may evoke a pain response allodynia As a result of nociceptor activity after tissue injury or inflammation a number of changes occur in the central nervous system These include changes to dorsal horn transmission neuron receptors leading the transmission neurons to become increasingly responsive to peripheral input central sensitization with reduction in the threshold for mechanically induced pain and an expansion of the receptive field of dorsal horn neurons spatial summation Radiating pain in OA likely reflects this latter phenomenon Once established central sensitization is maintained by lowlevel noxious and even nonnociceptive input from the periphery Such changes in the central nervous system are mainly responsible for the enhanced sensitivity to mechanical stimuli that develops outside the area of the injury secondary hyperalgesia',\n",
       "  'Beyond the clinical observations of hyperalgesia allodynia and radiating pain that suggest a role for sensitization in OArelated pain there are some experimental neurophysiologic findings that also support the presence of sensitization in OA Persons with knee OA experience a greater intensity duration and area of hyperalgesia after intramuscular injection of hypertonic saline compared with controls Lidocaine injected into a painful OA knee resulted in pain reduction in both the injected knee and the untreated contralateral knee supporting central pain modulation in OA Persons with knee OA have higher pain intensities compared with controls to the same level of pressure stimuli as well as lower pressure pain thresholds Other studies have also documented lower pain thresholds in persons with OA compared with controls Temporal summation a progressive increase in discharges of dorsal horn neurons in response to repetitive afferent stimulation thought to reflect central sensitization is increased in persons with painful knee OA compared with agematched healthy controls and the degree of sensitization correlated with pain What pathologies of OA may contribute to peripheral andor central sensitization other risk factors for sensitization and identification of the transition from appropriate nociceptive input to sensitization are important research questions that need to be addressed for improved understanding of pain mechanisms in OA In addition further development and validation of tools to assess sensitization will be necessary to support such research efforts',\n",
       "  'Thus there appears to be substantial opportunities to gain further insights into causes and contributors to pain in OA Such insights in turn will provide opportunities for rational mechanismbased targeting of pain for more efficacious therapeutic management of OA patients',\n",
       "  'Because effective treatment for OA and its related pain is not available to date and the disease can be present for decades the public health impact of OA is substantial on an individual and societal level Figure 1 With the high prevalence of knee OA globally not only is OA a leading cause of disability among older adults in the US but it is among the top 10 causes of disability worldwide In recent estimates of global years lived in disability musculoskeletalrelated conditions ranked second with low back pain neck pain and knee OA being the three most common such conditions and knee OA itself ranked within the top 10 noncommunicable diseases for global disabilityadjusted life years ie years of life lost and years lived with disability',\n",
       "  'Symptoms such as pain stiffness and gelling in OA have clear contributions to functional limitations in OA with welldocumented associations of pain severity with degree of functional limitation While most of the research focus to date has been on the knee or hip symptomatic hand OA has important functional limitations predominantly related to weaker grip strength and activities requiring precise pincer grip or power grip Nonetheless a particular focus on lower extremity OA is warranted given the high prevalence of associated disability In a longitudinal panel survey conducted by the US Census bureau arthritis or rheumatism was the most commonly reported cause of disability and difficulties related to lower extremity functioning or activities were the most commonly reported limitations among all respondents Specifically the most common limitation was in walking 3 city blocks which affected an estimated 225 million US adults and difficulty with climbing stairs affecting an estimated 217 million US adults While not all such individuals have symptomatic knee or hip OA it is likely that OA accounts for a large proportion of these limitations Based upon NHANES III data among persons with OA about 80 have some degree of movement limitation and 25 cannot perform major activities of daily living 11 of adults with knee OA require help with personal care and 14 require help with routine needs Symptomatic knee OA can have less obviously apparent effects on functioning as well For example persons with knee OA have slower walking speeds than those without OA Further those with symptomatic knee OA have a faster decline in gait speed over time than those with either knee OA alone or knee pain alone It is not surprising that knee pain also leads to restrictions in mobility outside of the house impacting upon participation',\n",
       "  'Symptomatic OAs economic impact is also substantial Average direct medical charges related to OA care were estimated to be 2600 per year per individual in 1997 and the total ie direct and indirect annual disease costs were estimated to be 5700 per individual USD FY 2000 Those costs need to be considered in the context of the prevalence of the disease to appreciate the overall societal economic impact OA as a primary diagnosis accounted for 1125 million 223 of all arthritisrelated ambulatory medical care visits in 2006 Further arthritisrelated conditions were the second most common reason for medical visits related to chronic conditions in 2005 second only to hypertension which is asymptomatic In terms of inpatient costs OA was the fifth most expensive condition treated in US hospitals in 2008 with a cost of 40 billion in total national hospital expenditures comprising 35 of the national hospital bill and accounting for 70 of all arthritisrelated inpatient hospitalizations Much of those hospitalizations were related to joint replacement surgery Pain is clearly among the main reasons for individuals seeking joint replacement Knee replacement surgeries are one of the most commonly performed orthopedic procedures in the US with 50 of all joint arthoplasties performed on the knee and 97 of those are performed for knee OA In 2004 478000 knee replacement surgeries were performed representing a 3fold increase since 1991 with total hospitalization charges of 1426 billion in 2004 This increase exceeds expectations based upon overall population growth and increase in the proportion of the population that is elderly andor obese The demand for primary total knee replacement is expected to grow by 673 to 348 million procedures by 2030 Adding to these costs is the increase in health care utilization in the two years preceding the surgery',\n",
       "  'To appreciate the total economic burden of OA on society indirect or productivity costs must also be examined Productivity costs typically reflect costs due to lost productivity while being present at work costs due to absence from work and costs for compensation of household work by others Unfortunately there are significant variations among indirect cost studies in OA regarding methodology cost estimation and cost presentation limiting ones ability to determine the magnitude of OAs economic impact For example in one review indirect costs of OA per patient per year varied from 831 in Hong Kong to 12789 in Canada costs in 2006 USD Considering the prevalence of OA workrelated OA costs have been estimated to range from 34 to 132 billion per year Estimates from 1999 indicate that adults with knee OA reported more than 13 days of lost work due to health issues Using a more recent large US employer benefits database those with OA had an average of 63 days of absenteeism compared with 37 days among a matched comparator group with mean total direct and indirect costs being 2 to 3fold higher Similar findings were noted in a Swedish populationbased cohort in which those with physiciandiagnosed knee OA had a 2fold increased risk of sick leave and 4050 increased risk of disability pension compared with the general population Further 2 of all sick days in the population were attributable to knee OA In a systematic literature review regarding work participation occupational limitations and reduced work capacity or job effectiveness were reported more frequently in those with OA than by controls Aggregate annual absenteeism costs of OA were estimated to be 10 billion from the US Medical Expenditure Panel Survey higher than many other major chronic diseases Taking into account both productivity costs and medical costs among adults with paid employment in a study from the Netherlands the total economic burden of knee OA was estimated to be 871 per person per month with the majority of the costs being related to productivity Regardless of the methodologic differences issues with cost estimation and difficulties in comparing costs across studies it is clear that OA has a tremendous economic impact that will only continue to grow with its rising prevalence',\n",
       "  'OA is highly prevalent worldwide with a tremendous symptomatic and economic global burden Although a number of risk factors have been identified for pain in OA the research focus to date has primarily been on structural targets Pharmacologic treatment options remain limited and nonpharmacologic options are underutilized An expansion of the research agenda to more fully explore pain mechanisms operational in OA is urgently needed to enable comprehensive mechanismbased pain management strategies in this prevalent disabling and costly disease',\n",
       "  'This is a PDF file of an unedited manuscript that has been accepted for publication As a service to our customers we are providing this early version of the manuscript The manuscript will undergo copyediting typesetting and review of the resulting proof before it is published in its final citable form Please note that during the production process errors may be discovered which could affect the content and all legal disclaimers that apply to the journal pertain',\n",
       "  'The natural history of disability and its determinants in adults with lower limb musculoskeletal pain',\n",
       "  'Healthrelated quality of life and health service use among older adults with osteoarthritis',\n",
       "  'Prevalence of disabilities and associated health conditions among adults United States 1999',\n",
       "  'The effects of specific medical conditions on the functional limitations of elders in the Framingham Study',\n",
       "  'Estimates of the prevalence of arthritis and other rheumatic conditions in the United States Part II',\n",
       "  'The prevalence of knee osteoarthritis in the elderly The Framingham Osteoarthritis Study',\n",
       "  'Prevalence of knee symptoms and radiographic and symptomatic knee osteoarthritis in African Americans and Caucasians the Johnston County Osteoarthritis Project',\n",
       "  'Knee pain and osteoarthritis in older adults a review of community burden and current use of primary health care',\n",
       "  'Prevalence of hip symptoms and radiographic and symptomatic hip osteoarthritis in African Americans and Caucasians the Johnston County Osteoarthritis Project',\n",
       "  'Prevalence incidence and progression of hand osteoarthritis in the general population the Framingham Osteoarthritis Study',\n",
       "  'Prevalence of symptomatic hand osteoarthritis and its impact on functional status among the elderly The Framingham Study',\n",
       "  'Symptomatic hand osteoarthritis in the United States prevalence and functional impairment estimates from the third US National Health and Nutrition Examination Survey 19911994',\n",
       "  'Increasing prevalence of knee pain and symptomatic knee osteoarthritis survey and cohort data',\n",
       "  'Projections of US prevalence of arthritis and associated activity limitations',\n",
       "  'Understanding the pain experience in hip and knee osteoarthritisan OARSIOMERACT initiative',\n",
       "  'Being careful a grounded theory of emergent chronic knee problems',\n",
       "  'Daily pain variations among patients with hand hip and knee osteoarthritis',\n",
       "  'Validation study of WOMAC a health status instrument for measuring clinically important patient relevant outcomes to antirheumatic drug therapy in patients with osteoarthritis of the hip or knee',\n",
       "  'The Knee injury and Osteoarthritis Outcome Score KOOS from joint injury to osteoarthritis',\n",
       "  'Measures of adult pain Visual Analog Scale for Pain VAS Pain Numeric Rating Scale for Pain NRS Pain McGill Pain Questionnaire MPQ ShortForm McGill Pain Questionnaire SFMPQ Chronic Pain Grade Scale CPGS Short Form36 Bodily Pain Scale SF36 BPS and Measure of Intermittent and Constant Osteoarthritis Pain ICOAP',\n",
       "  'Outcome measures in placebocontrolled trials of osteoarthritis responsiveness to treatment effects in the REPORT database',\n",
       "  'OMERACTOARSI initiative Osteoarthritis Research Society International set of responder criteria for osteoarthritis clinical trials revisited',\n",
       "  'Hip disability and osteoarthritis outcome score An extension of the Western Ontario and McMaster Universities Osteoarthritis Index',\n",
       "  'Clinimetric properties of the AUSCAN Osteoarthritis Hand Index an evaluation of reliability validity and responsiveness',\n",
       "  'Development and preliminary psychometric testing of a new OA pain measurean OARSIOMERACT initiative',\n",
       "  'Responsiveness of the OARSIOMERACT osteoarthritis pain and function measures',\n",
       "  'Core outcome measures for chronic pain clinical trials IMMPACT recommendations',\n",
       "  'Core outcome domains for chronic pain clinical trials IMMPACT recommendations',\n",
       "  'Relationship between symptoms and structural change in osteoarthritis what are the important targets for osteoarthritis therapy',\n",
       "  'Correlates of knee pain among US adults with and without radiographic knee osteoarthritis',\n",
       "  'Analysis of the discordance between radiographic changes and knee pain in osteoarthritis of the knee',\n",
       "  'Epidemiologic associations of pain in osteoarthritis of the knee data from the National Health and Nutrition Examination Survey and the National Health and Nutrition ExaminationI Epidemiologic Followup Survey',\n",
       "  'Determinants of pain severity in knee osteoarthritis effect of demographic and psychosocial variables using 3 pain measures',\n",
       "  'Association of radiographic features of osteoarthritis of the knee with knee pain data from the Baltimore Longitudinal Study of Aging',\n",
       "  'The discordance between clinical and radiographic knee osteoarthritis a systematic search and summary of the literature',\n",
       "  'Symptoms and radiographic osteoarthritis not as discordant as they are made out to be',\n",
       "  'Associations between pain function and radiographic features in osteoarthritis of the knee',\n",
       "  'Pain mechanisms in osteoarthritis of the knee effect of intraarticular anesthetic',\n",
       "  'Regional mu opioid receptor regulation of sensory and affective dimensions of pain',\n",
       "  'The genetic mediation of individual differences in sensitivity to pain and its inhibition',\n",
       "  'A comparison of placebo effects in clinical analgesic trials versus studies of placebo analgesia',\n",
       "  'Expectations and anxiety as mediators of placebo effects in pain',\n",
       "  'Effects of odors on pain perception deciphering the roles of emotion and attention',\n",
       "  'Social environment moderates the association between catastrophizing and pain among persons with a spinal cord injury',\n",
       "  'Is emotional disturbance a precipitator or a consequence of chronic pain',\n",
       "  'Relationship between social desirability and selfreport in chronic pain patients',\n",
       "  'Association between radiographic features of knee osteoarthritis and pain results from two cohort studies',\n",
       "  'Radiographic osteoarthritis severity is associated with an increased risk of developing knee pain Findings from the Osteoarthritis Initiative',\n",
       "  'Do knee abnormalities visualised on MRI explain knee pain in knee osteoarthritis A systematic review',\n",
       "  'Zoledronic acid reduces knee pain and bone marrow lesions over 1 year a randomised controlled trial',\n",
       "  'Efficacy and safety of strontium ranelate in the treatment of knee osteoarthritis results of a doubleblind randomised placebocontrolled trial',\n",
       "  'Pain coping skills training and lifestyle behavioral weight management in patients with knee osteoarthritis a randomized controlled study',\n",
       "  'Pain coping skills training for patients with elevated pain catastrophizing who are scheduled for knee arthroplasty a quasiexperimental study',\n",
       "  'Racial differences in osteoarthritis pain and function potential explanatory factors',\n",
       "  'Negative affect pain and disability in osteoarthritis patients the mediating role of muscle weakness',\n",
       "  'A longitudinal study to explain the paindepression link in older adults with osteoarthritis',\n",
       "  'Psychophysical and functional imaging evidence supporting the presence of central sensitization in a cohort of osteoarthritis patients',\n",
       "  'Arthritic pain is processed in brain areas concerned with emotions and fear',\n",
       "  'Metabolic factors in osteoarthritis obese people do not walk on their hands',\n",
       "  'Weight loss reduces the risk for symptomatic knee osteoarthritis in women The Framingham Study',\n",
       "  'Weight loss as treatment for knee osteoarthritis symptoms in obese patients 1year results from a randomised controlled trial',\n",
       "  'Exercise and dietary weight loss in overweight and obese older adults with knee osteoarthritis the Arthritis Diet and Activity Promotion Trial',\n",
       "  'The Intenstive Diet and Exercise for Arthritis Trial 18month clinical outcomes',\n",
       "  'Benefits of massive weight loss on symptoms systemic inflammation and cartilage turnover in obese patients with knee osteoarthritis',\n",
       "  'Body weight changes and corresponding changes in pain and function in persons with symptomatic knee osteoarthritis A cohort study',\n",
       "  'A functional polymorphism in the catecholOmethyltransferase gene is associated with osteoarthritisrelated pain',\n",
       "  'The Ile585Val TRPV1 variant is involved in risk of painful knee osteoarthritis',\n",
       "  'A role for PACE4 in osteoarthritis pain evidence from human genetic association and null mutant phenotype',\n",
       "  'Role of the Nav1 7 R1150W amino acid change in susceptibility to symptomatic knee osteoarthritis and multiple regional pain',\n",
       "  'Genetically determined P2X7 receptor pore formation regulates variability in chronic pain sensitivity',\n",
       "  'Signaling pathways in sensitization toward a nociceptor cell biology',\n",
       "  'Evidence for a central component of postinjury pain hypersensitivity',\n",
       "  'Different patterns of hyperalgesia induced by experimental inflammation in human skin',\n",
       "  'Osteoarthritis and its association with muscle hyperalgesia an experimental controlled study',\n",
       "  'Lessons from fibromyalgia abnormal pain sensitivity in knee osteoarthritis',\n",
       "  'Impact of nervous system hyperalgesia on pain disability and quality of life in patients with knee osteoarthritis a controlled analysis',\n",
       "  'The reliability and validity of pain threshold measurements in osteoarthritis of the knee',\n",
       "  'Quantitative sensory testing in painful osteoarthritis a systematic review and metaanalysis',\n",
       "  'Years lived with disability YLDs for 1160 sequelae of 289 diseases and injuries 19902010 a systematic analysis for the Global Burden of Disease Study 2010',\n",
       "  'Disabilityadjusted life years DALYs for 291 diseases and injuries in 21 regions 19902010 a systematic analysis for the Global Burden of Disease Study 2010',\n",
       "  'Predicting the course of functional limitation among older adults with knee pain do local signs symptoms and radiographs add anything to general indicators',\n",
       "  'Factors associated with functional impairment in symptomatic knee osteoarthritis',\n",
       "  'Prevalence of symptomatic hand osteoarthritis and its impact on functional status among the elderly The Framingham Study',\n",
       "  'Prevalence and Most Common Causes of Disability Among Adults United States 2005',\n",
       "  'A study of the gait characteristics of patients with chronic osteoarthritis of the knee',\n",
       "  'Is symptomatic knee osteoarthritis a risk factor for a fast decline in gait speed Results from the Osteoarthritis Initiative',\n",
       "  'Factors associated with restricted mobility outside the home in communitydwelling adults ages fifty years and older with knee pain an example of use of the International Classification of Functioning to investigate participation restriction',\n",
       "  'The economic burden associated with osteoarthritis rheumatoid arthritis and hypertension a comparative study',\n",
       "  'The National Hospital Bill The Most Expensive Conditions by Payer 2008',\n",
       "  'Prevalence of primary and revision total hip and knee arthroplasty in the United States from 1990 through 2002',\n",
       "  'Projections of primary and revision hip and knee arthroplasty in the United States from 2005 to 2030',\n",
       "  'Patterns of pharmacotherapy and health care utilization and costs prior to total hip or total knee replacement in patients with osteoarthritis',\n",
       "  'Productivity costs and medical costs among working patients with knee osteoarthritis',\n",
       "  'The need for standardization a literature review of indirect costs of rheumatoid arthritis and osteoarthritis',\n",
       "  'Direct and indirect economic costs among privatesector employees with osteoarthritis',\n",
       "  'Risk of sick leave and disability pension in workingage women and men with knee osteoarthritis',\n",
       "  'The effect of osteoarthritis of the hip or knee on work participation',\n",
       "  'Osteoarthritis and absenteeism costs evidence from US National Survey Data',\n",
       "  'Schematic illustrating the multifactorial nature of pain in OA with complex interrelationships between various risk factors and the potential wideranging effects of OA pain']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_dict))\n",
    "data_dict['Arthralgias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Document text arrangement to search using FIASS Index.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2992/2992 [00:34<00:00, 86.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "medQA_Filtered_data = []\n",
    "\n",
    "for key, data in tqdm(data_dict.items()):\n",
    "        for texts in data:\n",
    "            for text in texts:\n",
    "                if len(text.split())>10:\n",
    "                    medQA_Filtered_data.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849033"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(medQA_Filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                     | 5791/849033 [1:04:01<155:22:29,  1.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[1;32m----> 8\u001b[0m fiass_embeddings \u001b[38;5;241m=\u001b[39m getEmbeddingsListwise(medQA_Filtered_data)\n",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m, in \u001b[0;36mgetEmbeddingsListwise\u001b[1;34m(data_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(data_list):\n\u001b[1;32m----> 4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m get_embeddings(text,bert_tokenizer, bert_model)\n\u001b[0;32m      5\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(texts, tokenizer, model)\u001b[0m\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# No need to compute gradients\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     23\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m     24\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m last_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1142\u001b[0m     embedding_output,\n\u001b[0;32m   1143\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1144\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1145\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1146\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1148\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1149\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1150\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1151\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1152\u001b[0m )\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    695\u001b[0m         hidden_states,\n\u001b[0;32m    696\u001b[0m         attention_mask,\n\u001b[0;32m    697\u001b[0m         layer_head_mask,\n\u001b[0;32m    698\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    699\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    700\u001b[0m         past_key_value,\n\u001b[0;32m    701\u001b[0m         output_attentions,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    585\u001b[0m         hidden_states,\n\u001b[0;32m    586\u001b[0m         attention_mask,\n\u001b[0;32m    587\u001b[0m         head_mask,\n\u001b[0;32m    588\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    589\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[0;32m    590\u001b[0m     )\n\u001b[0;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m    516\u001b[0m         attention_mask,\n\u001b[0;32m    517\u001b[0m         head_mask,\n\u001b[0;32m    518\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    519\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    520\u001b[0m         past_key_value,\n\u001b[0;32m    521\u001b[0m         output_attentions,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[0;32m    523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    437\u001b[0m )\n\u001b[1;32m--> 439\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(\n\u001b[0;32m    440\u001b[0m     query_layer,\n\u001b[0;32m    441\u001b[0m     key_layer,\n\u001b[0;32m    442\u001b[0m     value_layer,\n\u001b[0;32m    443\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    444\u001b[0m     dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_prob \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m    445\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    448\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def getEmbeddingsListwise(data_list):\n",
    "    embeddings = []\n",
    "    for text in tqdm(data_list):\n",
    "        embedding = get_embeddings(text,bert_tokenizer, bert_model)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "fiass_embeddings = getEmbeddingsListwise(medQA_Filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIASS Installation and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu \n",
    "#pip install faiss-gpu  # For GPU support, if you have a CUDA-capable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Get the dimensionality of the embeddings\n",
    "embedding_dim = embeddings.shape[1]\n",
    "\n",
    "# Create a FAISS index\n",
    "# IndexFlatL2 is a simple, exact nearest neighbor search index with L2 distance\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Check the number of vectors in the index\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")\n",
    "\n",
    "# Save the index to a file for later use\n",
    "faiss.write_index(index, 'FAISS\\QA200_327_index.index')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS index\n",
    "faiss_index = faiss.read_index('FAISS\\QA200_327_index.index')\n",
    "\n",
    "# Function to search the FAISS index\n",
    "def search_faiss_index(query, index, tokenizer, model, top_k=5):\n",
    "    # Compute the query embedding\n",
    "    query_embedding = get_embeddings(query, tokenizer, model)\n",
    "\n",
    "    # Reshape the query embedding to match FAISS expected input format\n",
    "    query_embedding = np.expand_dims(query_embedding, axis=0).astype('float32')\n",
    "\n",
    "    # Search the FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"Nitrofurantoin\"\n",
    "top_k = 5\n",
    "\n",
    "distances, indices = search_faiss_index(query, index, bert_tokenizer, bert_model, top_k=top_k)\n",
    "\n",
    "# Print results\n",
    "print(f\"Top-{top_k} results:\")\n",
    "for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "    print(f\"Result {i + 1}:\")\n",
    "    print(f\"Index: {idx}, Distance: {distance}\")\n",
    "    # If you have the original text stored, you can retrieve it like this:\n",
    "    # print(f\"Text: {embeddings_dict['some_key'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T10:05:21.030809Z",
     "iopub.status.busy": "2024-07-12T10:05:21.029959Z",
     "iopub.status.idle": "2024-07-12T10:07:13.865645Z",
     "shell.execute_reply": "2024-07-12T10:07:13.864647Z",
     "shell.execute_reply.started": "2024-07-12T10:05:21.030777Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
      "  Downloading langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.98-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.9.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.1)\n",
      "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "   ---------------------------------------- 0.0/990.6 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/990.6 kB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 990.6/990.6 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
      "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.98-py3-none-any.whl (140 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.6-cp311-none-win_amd64.whl (136 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging, orjson, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed jsonpatch-1.33 langchain-0.2.12 langchain-core-0.2.29 langchain-text-splitters-0.2.2 langsmith-0.1.98 orjson-3.10.6 packaging-24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ranad\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: boto3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (1.26.76)\n",
      "Requirement already satisfied: requests in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.76 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.29.76)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: six in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from tqdm->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from botocore<1.30.0,>=1.29.76->boto3->transformers) (2.8.2)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/991.5 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from accelerate) (2.2.0)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Downloading safetensors-0.4.4-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.21.0->accelerate)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Downloading safetensors-0.4.4-cp311-none-win_amd64.whl (285 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, accelerate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.33.0 fsspec-2024.6.1 huggingface-hub-0.24.5 safetensors-0.4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.6.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from bitsandbytes) (1.25.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.3-py3-none-win_amd64.whl (136.5 MB)\n",
      "   ---------------------------------------- 0.0/136.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/136.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/136.5 MB 2.6 MB/s eta 0:00:52\n",
      "   ---------------------------------------- 1.3/136.5 MB 2.2 MB/s eta 0:01:01\n",
      "    --------------------------------------- 2.1/136.5 MB 2.6 MB/s eta 0:00:52\n",
      "    --------------------------------------- 2.6/136.5 MB 2.8 MB/s eta 0:00:48\n",
      "    --------------------------------------- 2.9/136.5 MB 2.3 MB/s eta 0:00:58\n",
      "    --------------------------------------- 3.4/136.5 MB 2.3 MB/s eta 0:00:59\n",
      "   - -------------------------------------- 3.9/136.5 MB 2.3 MB/s eta 0:00:57\n",
      "   - -------------------------------------- 4.2/136.5 MB 2.4 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 4.5/136.5 MB 2.3 MB/s eta 0:00:59\n",
      "   - -------------------------------------- 5.0/136.5 MB 2.2 MB/s eta 0:01:01\n",
      "   - -------------------------------------- 5.2/136.5 MB 2.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 6.0/136.5 MB 2.2 MB/s eta 0:01:00\n",
      "   - -------------------------------------- 6.3/136.5 MB 2.2 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 7.1/136.5 MB 2.2 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 7.9/136.5 MB 2.3 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 8.4/136.5 MB 2.3 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 8.7/136.5 MB 2.3 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 9.2/136.5 MB 2.3 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 9.4/136.5 MB 2.3 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 9.7/136.5 MB 2.2 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 10.2/136.5 MB 2.2 MB/s eta 0:00:58\n",
      "   --- ------------------------------------ 10.7/136.5 MB 2.2 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 11.3/136.5 MB 2.3 MB/s eta 0:00:56\n",
      "   --- ------------------------------------ 11.5/136.5 MB 2.2 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 12.1/136.5 MB 2.2 MB/s eta 0:00:57\n",
      "   --- ------------------------------------ 13.1/136.5 MB 2.3 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 13.4/136.5 MB 2.3 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 13.6/136.5 MB 2.2 MB/s eta 0:00:55\n",
      "   ---- ----------------------------------- 14.4/136.5 MB 2.3 MB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 15.2/136.5 MB 2.3 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 16.0/136.5 MB 2.4 MB/s eta 0:00:51\n",
      "   ---- ----------------------------------- 16.5/136.5 MB 2.4 MB/s eta 0:00:50\n",
      "   ---- ----------------------------------- 16.8/136.5 MB 2.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 17.3/136.5 MB 2.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 17.8/136.5 MB 2.3 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 18.6/136.5 MB 2.4 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 19.1/136.5 MB 2.4 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 19.9/136.5 MB 2.4 MB/s eta 0:00:48\n",
      "   ------ --------------------------------- 20.7/136.5 MB 2.5 MB/s eta 0:00:47\n",
      "   ------ --------------------------------- 21.8/136.5 MB 2.5 MB/s eta 0:00:46\n",
      "   ------ --------------------------------- 22.0/136.5 MB 2.5 MB/s eta 0:00:46\n",
      "   ------ --------------------------------- 22.5/136.5 MB 2.5 MB/s eta 0:00:46\n",
      "   ------ --------------------------------- 23.3/136.5 MB 2.5 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 24.1/136.5 MB 2.6 MB/s eta 0:00:44\n",
      "   ------- -------------------------------- 25.2/136.5 MB 2.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 25.4/136.5 MB 2.6 MB/s eta 0:00:44\n",
      "   ------- -------------------------------- 26.2/136.5 MB 2.6 MB/s eta 0:00:43\n",
      "   ------- -------------------------------- 27.0/136.5 MB 2.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 27.5/136.5 MB 2.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 28.0/136.5 MB 2.6 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 29.1/136.5 MB 2.7 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 29.9/136.5 MB 2.7 MB/s eta 0:00:40\n",
      "   -------- ------------------------------- 30.4/136.5 MB 2.7 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 30.9/136.5 MB 2.7 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 31.5/136.5 MB 2.7 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 32.0/136.5 MB 2.7 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 32.8/136.5 MB 2.7 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 33.3/136.5 MB 2.7 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 33.8/136.5 MB 2.7 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 34.6/136.5 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 34.9/136.5 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 35.1/136.5 MB 2.6 MB/s eta 0:00:39\n",
      "   ---------- ----------------------------- 35.9/136.5 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 36.4/136.5 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 36.7/136.5 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 37.2/136.5 MB 2.6 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 38.3/136.5 MB 2.7 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 38.5/136.5 MB 2.7 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 38.8/136.5 MB 2.6 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 39.3/136.5 MB 2.6 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 39.8/136.5 MB 2.6 MB/s eta 0:00:37\n",
      "   ----------- ---------------------------- 40.6/136.5 MB 2.6 MB/s eta 0:00:37\n",
      "   ------------ --------------------------- 41.4/136.5 MB 2.7 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 41.9/136.5 MB 2.6 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 42.7/136.5 MB 2.7 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 43.3/136.5 MB 2.7 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 43.8/136.5 MB 2.7 MB/s eta 0:00:35\n",
      "   ------------ --------------------------- 44.0/136.5 MB 2.6 MB/s eta 0:00:36\n",
      "   ------------ --------------------------- 44.3/136.5 MB 2.6 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 44.8/136.5 MB 2.6 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 45.6/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 45.6/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 46.1/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 46.9/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 47.2/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 47.7/136.5 MB 2.6 MB/s eta 0:00:35\n",
      "   -------------- ------------------------- 48.5/136.5 MB 2.6 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 49.3/136.5 MB 2.6 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 50.1/136.5 MB 2.6 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 50.6/136.5 MB 2.6 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 50.9/136.5 MB 2.6 MB/s eta 0:00:33\n",
      "   --------------- ------------------------ 51.6/136.5 MB 2.6 MB/s eta 0:00:33\n",
      "   --------------- ------------------------ 52.4/136.5 MB 2.6 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 53.2/136.5 MB 2.6 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 54.0/136.5 MB 2.7 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 54.5/136.5 MB 2.7 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 55.3/136.5 MB 2.7 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 55.8/136.5 MB 2.7 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 56.4/136.5 MB 2.7 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 56.6/136.5 MB 2.7 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 57.1/136.5 MB 2.7 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 57.9/136.5 MB 2.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 58.7/136.5 MB 2.7 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 59.2/136.5 MB 2.7 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 59.8/136.5 MB 2.7 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 60.6/136.5 MB 2.7 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 60.8/136.5 MB 2.7 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 61.9/136.5 MB 2.7 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 62.7/136.5 MB 2.7 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 63.2/136.5 MB 2.7 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 64.0/136.5 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 64.5/136.5 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 65.3/136.5 MB 2.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 66.1/136.5 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 67.1/136.5 MB 2.7 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 67.6/136.5 MB 2.7 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 68.4/136.5 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 69.2/136.5 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 69.5/136.5 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 70.0/136.5 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 70.8/136.5 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 71.6/136.5 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 72.4/136.5 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 72.9/136.5 MB 2.8 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 73.4/136.5 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 74.2/136.5 MB 2.8 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 74.4/136.5 MB 2.8 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 75.2/136.5 MB 2.8 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 75.8/136.5 MB 2.8 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 76.3/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 76.8/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 77.3/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 77.9/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 78.1/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 78.4/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 78.9/136.5 MB 2.7 MB/s eta 0:00:22\n",
      "   ----------------------- ---------------- 79.4/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 80.0/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 80.5/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 81.0/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 81.5/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 81.8/136.5 MB 2.7 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 82.6/136.5 MB 2.7 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 83.1/136.5 MB 2.7 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 83.4/136.5 MB 2.7 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 83.9/136.5 MB 2.7 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 84.4/136.5 MB 2.7 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 85.2/136.5 MB 2.7 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 85.7/136.5 MB 2.7 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 86.5/136.5 MB 2.7 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 87.3/136.5 MB 2.7 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 88.1/136.5 MB 2.8 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 88.9/136.5 MB 2.8 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 89.7/136.5 MB 2.8 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 90.4/136.5 MB 2.8 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 91.0/136.5 MB 2.8 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 91.8/136.5 MB 2.8 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 92.0/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 92.8/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 93.3/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 93.6/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 93.8/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 94.4/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 94.6/136.5 MB 2.8 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 95.4/136.5 MB 2.8 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 95.7/136.5 MB 2.8 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 96.2/136.5 MB 2.8 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 96.7/136.5 MB 2.8 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 97.3/136.5 MB 2.8 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 97.8/136.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 98.6/136.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 99.1/136.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 99.4/136.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 99.9/136.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 100.7/136.5 MB 2.8 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 101.2/136.5 MB 2.8 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 101.4/136.5 MB 2.8 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 102.0/136.5 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 103.0/136.5 MB 2.8 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 103.5/136.5 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 103.8/136.5 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 104.6/136.5 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 105.1/136.5 MB 2.8 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 105.6/136.5 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 106.2/136.5 MB 2.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 106.7/136.5 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 107.0/136.5 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 107.7/136.5 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 108.5/136.5 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 109.1/136.5 MB 2.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 109.6/136.5 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 110.4/136.5 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 111.1/136.5 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 111.4/136.5 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 111.9/136.5 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 112.5/136.5 MB 2.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 113.2/136.5 MB 2.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 113.8/136.5 MB 2.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 114.3/136.5 MB 2.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 115.1/136.5 MB 2.7 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 115.9/136.5 MB 2.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 116.7/136.5 MB 2.7 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 117.7/136.5 MB 2.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 118.5/136.5 MB 2.7 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 118.8/136.5 MB 2.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 119.5/136.5 MB 2.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 120.1/136.5 MB 2.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 120.8/136.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 121.6/136.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 121.9/136.5 MB 2.8 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 122.7/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 123.2/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 123.7/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 124.5/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 125.0/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 125.3/136.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 125.6/136.5 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 126.4/136.5 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 126.9/136.5 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 127.7/136.5 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 127.9/136.5 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 128.7/136.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 129.2/136.5 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 130.0/136.5 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 130.5/136.5 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 131.3/136.5 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 132.1/136.5 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 132.6/136.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  133.2/136.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  133.7/136.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  134.2/136.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  135.0/136.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  135.8/136.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  136.3/136.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  136.3/136.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.5/136.5 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ranad\\anaconda3\\lib\\site-packages (24.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\ranad\\anaconda3\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (0.2.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (0.1.98)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.1)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.29)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.98)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (1.25.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.5.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.14.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 985.5 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.3 MB 985.5 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.3 MB 729.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.0/2.3 MB 967.3 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.6/2.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.11 marshmallow-3.21.3 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.24.5)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.2.29)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface)\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.98)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.5.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.2.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2023.11.17)\n",
      "Requirement already satisfied: sympy in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ranad\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.5 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.4/9.5 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.9/9.5 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.4/9.5 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.2/9.5 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.7/9.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers, sentence-transformers, langchain-huggingface\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.1.1\n",
      "    Uninstalling transformers-2.1.1:\n",
      "      Successfully uninstalled transformers-2.1.1\n",
      "Successfully installed langchain-huggingface-0.0.3 sentence-transformers-3.0.1 tokenizers-0.19.1 transformers-4.44.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain\n",
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !pip install bitsandbytes\n",
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade langchain\n",
    "# !pip install langchain_community\n",
    "# !pip list | grep langchain\n",
    "# !pip list | grep langchain_community\n",
    "\n",
    "# !pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the pipeline with the langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T11:18:28.944831Z",
     "iopub.status.busy": "2024-07-12T11:18:28.944018Z",
     "iopub.status.idle": "2024-07-12T11:20:28.385866Z",
     "shell.execute_reply": "2024-07-12T11:20:28.385117Z",
     "shell.execute_reply.started": "2024-07-12T11:18:28.944793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca299f3601f846499256f0fe028122af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import langchain\n",
    "\n",
    "### prompts\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "### models\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "\n",
    "#model = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n",
    "#model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "#model = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model = \"Undi95/Meta-Llama-3-8B-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "        \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    ")\n",
    "\n",
    "model_llama = AutoModelForCausalLM.from_pretrained(\n",
    "    model,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    token='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T10:11:27.172667Z",
     "iopub.status.busy": "2024-07-12T10:11:27.171486Z",
     "iopub.status.idle": "2024-07-12T10:11:27.176608Z",
     "shell.execute_reply": "2024-07-12T10:11:27.175821Z",
     "shell.execute_reply.started": "2024-07-12T10:11:27.172632Z"
    }
   },
   "outputs": [],
   "source": [
    "question = questions_data[0]['question']\n",
    "options = \"\\nA. Ampicillin\\nB. Ceftriaxone\\nC. Doxycycline\\nD. Nitrofurantoin\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt generation\n",
    "template_context = f\"\"\"Question: {question}\n",
    "Context: {context}[INST]Select the correct option only. No explanation required[/INST]\n",
    "\n",
    "Options: {options}\n",
    "\n",
    "# Answer: \"\"\" # Force a single-line response\n",
    "\n",
    "prompt_context = PromptTemplate(template=template_context, input_variables=[\"question\", \"options\", \"context\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "inputs = tokenizer(prompt_context, return_tensors='pt', truncation=True, padding=\"max_length\", max_length=4000).to(model_llama.device)\n",
    "outputs = model_llama.generate(**inputs, max_new_tokens=1)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = response.find('#Answer:')\n",
    "prediction = response[position+8 :position+10].strip()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing a context summary prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the summarization prompt to generate a summary\n",
    "summarization_prompt = f\"\"\"[INST] Summarize the following text concisely:\n",
    "\n",
    "{context_text}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    summary_output = model_llama.generate(\n",
    "        **tokenizer(summarization_prompt, return_tensors=\"pt\").to(model_llama.device),\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    "\n",
    "# Decode and print the generated summary\n",
    "summary_text = tokenizer.decode(summary_output[0], skip_special_tokens=True)\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader with RAG using FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswerDataset_RAG(Dataset):\n",
    "    def __init__(self, questions_data, faiss_index, faiss_texts):\n",
    "        self.questionData = questions_data\n",
    "        self.faiss_index = faiss_index\n",
    "        self.faiss_texts = faiss_texts\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questionData)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question_data = self.questionData[idx]\n",
    "        question = question_data['question']\n",
    "        options = question_data['options']\n",
    "        options_str = \"\\n\".join([f\"{key}. {value}\" for key, value in options.items()])\n",
    "        answer = question_data['answer_idx']\n",
    "\n",
    "        # Search FAISS index for each option and retrieve the corresponding text\n",
    "        retrieved_contexts = []\n",
    "        for option_key, option_text in options.items():\n",
    "            option_embedding = self.get_text_embedding(option_text)\n",
    "            retrieved_indices = search_faiss_index(option_embedding, self.faiss_index)\n",
    "            retrieved_context = \" \".join([self.faiss_texts[i] for i in retrieved_indices])\n",
    "            retrieved_contexts.append(retrieved_context)\n",
    "\n",
    "        # Combine the contexts with the question and options for the final return\n",
    "        combined_context = \"\\n\".join(retrieved_contexts)\n",
    "\n",
    "        return question, options_str, answer, combined_context\n",
    "\n",
    "    def get_text_embedding(self, text):\n",
    "        # Placeholder for the actual embedding generation logic\n",
    "        # Replace this with the method to generate embeddings from text\n",
    "        return np.random.rand(768)  # Example: Replace with actual embedding\n",
    "\n",
    "\n",
    "faiss_texts = [...]  # Load the list of texts associated with the FAISS index\n",
    "\n",
    "# Load your dataset\n",
    "dataset_RAG = QuestionAnswerDataset_RAG(questions_data, faiss_index, faiss_texts)\n",
    "dataloader_RAG = DataLoader(dataset, batch_size=8, shuffle=False)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Batches with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T12:12:07.276303Z",
     "iopub.status.busy": "2024-07-12T12:12:07.275645Z",
     "iopub.status.idle": "2024-07-12T12:12:07.282846Z",
     "shell.execute_reply": "2024-07-12T12:12:07.281898Z",
     "shell.execute_reply.started": "2024-07-12T12:12:07.276271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10178"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "responses = []\n",
    "answers = []\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    questions, options_strs, answer_idxs, combined_contexts = batch\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    prompts = [prompt_context.format(question=question, options=options_str, context=combined_context) for question, options_str,combined_context in zip(questions, options_strs,combined_contexts)]\n",
    "    \n",
    "    inputs = tokenizer(prompts, return_tensors='pt', padding=True, truncation=True, max_length=4000).to(model_llama.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_llama.generate(**inputs,max_new_tokens=1)\n",
    "    \n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    #print(decoded_outputs)\n",
    "    for decoded_output, answer in zip(decoded_outputs, answer_idxs):\n",
    "        position = decoded_output.find('#Answer:')\n",
    "        answer_pred = decoded_output[position+8 :position+10].strip()\n",
    "        #print(answer_pred)\n",
    "        if answer == answer_pred.strip():\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        responses.append(answer_pred)\n",
    "        answers.append(answer)\n",
    "        total_predictions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {correct_predictions / len(responses):.2%}\")\n",
    "correct_predictions"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5259168,
     "sourceId": 8754656,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 3093,
     "sourceId": 4298,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 27739,
     "sourceId": 33146,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
